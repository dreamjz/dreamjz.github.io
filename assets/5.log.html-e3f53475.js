import{_ as o,Z as i,$ as l,a4 as n}from"./framework-d03928c9.js";const e={},g=n('<ul><li><strong>undo log（回滚日志）</strong>：是 Innodb 存储引擎层生成的日志，实现了事务中的<strong>原子性</strong>，主要<strong>用于事务回滚和 MVCC</strong>。</li><li><strong>redo log（重做日志）</strong>：是 Innodb 存储引擎层生成的日志，实现了事务中的<strong>持久性</strong>，主要<strong>用于掉电等故障恢复</strong>；</li><li><strong>binlog （归档日志）</strong>：是 Server 层生成的日志，主要<strong>用于数据备份和主从复制</strong>；</li></ul><h2 id="_2-1-undo-log-回滚日志" tabindex="-1"><a class="header-anchor" href="#_2-1-undo-log-回滚日志" aria-hidden="true">#</a> 2.1 undo log 回滚日志</h2><p><strong>undo log（回滚日志），它保证了事务的 ACID 中的原子性(Atomicity)</strong></p><p>undo log 是一种用于撤销回退的日志。在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚。如下图：</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/回滚事务.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="回滚事务" tabindex="0" loading="lazy"><figcaption>回滚事务</figcaption></figure><p>每当 InnoDB 引擎对一条记录进行操作（修改、删除、新增）时，要把回滚时需要的信息都记录到 undo log 里，比如：</p><ul><li>在<strong>插入</strong>一条记录时，要把这条记录的主键值记下来，这样之后回滚时只需要把这个主键值对应的记录<strong>删掉</strong>就好了；</li><li>在<strong>删除</strong>一条记录时，要把这条记录中的内容都记下来，这样之后回滚时再把由这些内容组成的记录<strong>插入</strong>到表中就好了；</li><li>在<strong>更新</strong>一条记录时，要把被更新的列的旧值记下来，这样之后回滚时再把这些列<strong>更新为旧值</strong>就好了。</li></ul><p>在发生回滚时，就读取 undo log 里的数据，然后做原先相反操作。</p><p>一条记录的每一次更新操作产生的 undo log 格式都有一个 roll_pointer 指针和一个 trx_id 事务id：</p><ul><li>通过 trx_id 可以知道该记录是被哪个事务修改的；</li><li>通过 roll_pointer 指针可以将这些 undo log 串成一个链表，这个链表就被称为版本链；</li></ul><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/版本链.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="版本链" tabindex="0" loading="lazy"><figcaption>版本链</figcaption></figure><p><strong>undo log 还有一个作用，通过 ReadView + undo log 实现 MVCC（多版本并发控制）</strong></p><p>对于「读提交」和「可重复读」隔离级别的事务来说，它们的快照读（普通 select 语句）是通过 Read View + undo log 来实现的，它们的区别在于创建 Read View 的时机不同：</p><ul><li>「读提交」隔离级别是在每个 select 都会生成一个新的 Read View，也意味着，事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。</li><li>「可重复读」隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View，这样就保证了在事务期间读到的数据都是事务启动前的记录。</li></ul><p>因此，undo log 两大作用：</p><ul><li><strong>实现事务回滚，保障事务的原子性</strong>。事务处理过程中，如果出现了错误或者用户执 行了 ROLLBACK 语句，MySQL 可以利用 undo log 中的历史数据将数据恢复到事务开始之前的状态。</li><li><strong>实现 MVCC（多版本并发控制）关键因素之一</strong>。MVCC 是通过 ReadView + undo log 实现的。undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的版本链找到满足其可见性的记录。</li></ul><h2 id="_2-2-buffer-pool" tabindex="-1"><a class="header-anchor" href="#_2-2-buffer-pool" aria-hidden="true">#</a> 2.2 Buffer Pool</h2><p>Innodb 存储引擎设计了一个<strong>缓冲池（Buffer Pool）</strong>，来提高数据库的读写性能。</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/mysql/innodb/缓冲池.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="Buffer Poo" tabindex="0" loading="lazy"><figcaption>Buffer Poo</figcaption></figure><ul><li>当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。</li><li>当修改数据时，如果数据存在于 Buffer Pool 中，那直接修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。</li></ul><h3 id="buffer-pool-内容" tabindex="-1"><a class="header-anchor" href="#buffer-pool-内容" aria-hidden="true">#</a> Buffer Pool 内容</h3><p>在 MySQL 启动的时候，<strong>InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的<code>16KB</code>的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页</strong>。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。</p><p>Buffer Pool 除了缓存「索引页」和「数据页」，还包括了 Undo 页，插入缓存、自适应哈希索引、锁信息等等。</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/mysql/innodb/bufferpool内容.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><h2 id="_2-3-redo-log" tabindex="-1"><a class="header-anchor" href="#_2-3-redo-log" aria-hidden="true">#</a> 2.3 redo log</h2><h3 id="wal" tabindex="-1"><a class="header-anchor" href="#wal" aria-hidden="true">#</a> WAL</h3><p>为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候，InnoDB 引擎就会先更新内存（同时标记为脏页），然后将本次对这个页的修改以 redo log 的形式记录下来，<strong>这个时候更新就算完成了</strong>。</p><p>后续，InnoDB 引擎会在适当的时候，由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里，这就是 <strong>WAL （Write-Ahead Logging）技术</strong>。</p><p><strong>WAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上</strong>。</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/wal.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>优点：</p><ul><li><strong>实现事务的持久性，让 MySQL 有 crash-safe 的能力</strong>，能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失；</li><li><strong>将写操作从「随机写」变成了「顺序写」</strong>，提升 MySQL 写入磁盘的性能。</li></ul><h3 id="redo-log" tabindex="-1"><a class="header-anchor" href="#redo-log" aria-hidden="true">#</a> redo log</h3><p>redo log 是物理日志，记录了某个数据页做了什么修改，比如<strong>对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新</strong>，每当执行一个事务就会产生这样的一条或者多条物理日志。</p><p>在事务提交时，只要先将 redo log 持久化到磁盘即可，可以不需要等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。</p><p>当系统崩溃时，虽然脏页数据没有持久化，但是 redo log 已经持久化，接着 MySQL 重启后，可以根据 redo log 的内容，将所有数据恢复到最新的状态。</p><h3 id="redo-log-和-undo-log-区别" tabindex="-1"><a class="header-anchor" href="#redo-log-和-undo-log-区别" aria-hidden="true">#</a> redo log 和 undo log 区别</h3><ul><li>redo log 记录了此次事务「<strong>完成后</strong>」的数据状态，记录的是更新<strong>之后</strong>的值；</li><li>undo log 记录了此次事务「<strong>开始前</strong>」的数据状态，记录的是更新<strong>之前</strong>的值；</li></ul><p>事务提交之前发生了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发生了崩溃，重启后会通过 redo log 恢复事务，如下图：</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/事务恢复.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="事务恢复" tabindex="0" loading="lazy"><figcaption>事务恢复</figcaption></figure><h3 id="redo-log-直接写入磁盘么" tabindex="-1"><a class="header-anchor" href="#redo-log-直接写入磁盘么" aria-hidden="true">#</a> redo log 直接写入磁盘么</h3><p>不是的。</p><p>执行一个事务的过程中，产生的 redo log 也不是直接写入磁盘的，因为这样会产生大量的 I/O 操作，而且磁盘的运行速度远慢于内存。</p><p>所以，redo log 也有自己的缓存—— <strong>redo log buffer</strong>，每当产生一条 redo log 时，会先写入到 redo log buffer，后续在持久化到磁盘如下图：</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/redologbuf.webp" alt="事务恢复" tabindex="0" loading="lazy"><figcaption>事务恢复</figcaption></figure><p>redo log buffer 默认大小 16 MB，可以通过 <code>innodb_log_Buffer_size</code> 参数动态的调整大小，增大它的大小可以让 MySQL 处理「大事务」是不必写入磁盘，进而提升写 IO 性能。</p><h3 id="redo-log-何时写入磁盘" tabindex="-1"><a class="header-anchor" href="#redo-log-何时写入磁盘" aria-hidden="true">#</a> redo log 何时写入磁盘</h3><p>主要有下面几个时机：</p><ul><li>MySQL 正常关闭时；</li><li>当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘；</li><li>InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。</li><li>每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘</li></ul><h4 id="innodb-flush-log-at-trx-commit" tabindex="-1"><a class="header-anchor" href="#innodb-flush-log-at-trx-commit" aria-hidden="true">#</a> innodb_flush_log_at_trx_commit</h4><p>单独执行一个更新语句的时候，InnoDB 引擎会自己启动一个事务，在执行更新语句的过程中，生成的 redo log 先写入到 redo log buffer 中，然后等事务提交的时候，再将缓存在 redo log buffer 中的 redo log 按组的方式「顺序写」到磁盘。</p><p>上面这种 redo log 刷盘时机是在事务提交的时候，这个默认的行为。</p><p>除此之外，InnoDB 还提供了另外两种策略，由参数 <code>innodb_flush_log_at_trx_commit</code> 参数控制，可取的值有：0、1、2，默认值为 1，这三个值分别代表的策略如下：</p><ul><li>当设置该<strong>参数为 0 时</strong>，表示每次事务提交时 ，还是<strong>将 redo log 留在 redo log buffer 中</strong> ，该模式下在事务提交时不会主动触发写入磁盘的操作。</li><li>当设置该<strong>参数为 1 时</strong>，表示每次事务提交时，都<strong>将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘</strong>，这样可以保证 MySQL 异常重启之后数据不会丢失。</li><li>当设置该<strong>参数为 2 时</strong>，表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log <strong>写到 redo log 文件，注意写入到「 redo log 文件」并不意味着写入到了磁盘</strong>，因为操作系统的文件系统中有个 Page Cache，Page Cache 是专门用来缓存文件数据的，所以写入「 redo log文件」意味着写入到了操作系统的文件缓存。</li></ul><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/innodb_flush_log_at_trx_commit.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><ul><li>针对参数 0 ：会把缓存在 redo log buffer 中的 redo log ，通过调用 <code>write()</code> 写到操作系统的 Page Cache，然后调用 <code>fsync()</code> 持久化到磁盘。<strong>所以参数为 0 的策略，MySQL 进程的崩溃会导致上一秒钟所有事务数据的丢失</strong>;</li><li>针对参数 2 ：调用 fsync，将缓存在操作系统中 Page Cache 里的 redo log 持久化到磁盘。<strong>所以参数为 2 的策略，较取值为 0 情况下更安全，因为 MySQL 进程的崩溃并不会丢失数据，只有在操作系统崩溃或者系统断电的情况下，上一秒钟所有事务数据才可能丢失</strong>。</li></ul><p>加入了后台现线程后，innodb_flush_log_at_trx_commit 的刷盘时机如下图：</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/innodb_flush_log_at_trx_commit2.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><h3 id="redo-log-如何写入文件" tabindex="-1"><a class="header-anchor" href="#redo-log-如何写入文件" aria-hidden="true">#</a> redo log 如何写入文件</h3><p>默认情况下， InnoDB 存储引擎有 1 个重做日志文件组( redo log Group），「重做日志文件组」由有 2 个 redo log 文件组成，这两个 redo 日志的文件名叫 ：<code>ib_logfile0</code> 和 <code>ib_logfile1</code> 。</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/重做日志文件组.drawio.png" alt="重做日志文件组" tabindex="0" loading="lazy"><figcaption>重做日志文件组</figcaption></figure><p>在重做日志组中，每个 redo log File 的大小是固定且一致的，假设每个 redo log File 设置的上限是 1 GB，那么总共就可以记录 2GB 的操作。</p><p>重做日志文件组是以<strong>循环写</strong>的方式工作的，从头开始写，写到末尾就又回到开头，相当于一个环形。</p><p>所以 InnoDB 存储引擎会先写 ib_logfile0 文件，当 ib_logfile0 文件被写满的时候，会切换至 ib_logfile1 文件，当 ib_logfile1 文件也被写满时，会切换回 ib_logfile0 文件。</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/重做日志文件组写入过程.drawio.png" alt="重做日志文件组写入过程" tabindex="0" loading="lazy"><figcaption>重做日志文件组写入过程</figcaption></figure><p>redo log 是为了防止 Buffer Pool 中的脏页丢失而设计的，那么如果随着系统运行，Buffer Pool 的脏页刷新到了磁盘中，那么 redo log 对应的记录也就没用了，这时候我们擦除这些旧记录，以腾出空间记录新的更新操作。</p><p>redo log 是循环写的方式，相当于一个环形，InnoDB 用 write pos 表示 redo log 当前记录写到的位置，用 checkpoint 表示当前要擦除的位置，如下图：</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/checkpoint.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>图中的：</p><ul><li>write pos 和 checkpoint 的移动都是顺时针方向；</li><li>write pos ～ checkpoint 之间的部分（图中的红色部分），用来记录新的更新操作；</li><li>check point ～ write pos 之间的部分（图中蓝色部分）：待落盘的脏数据页记录；</li></ul><p>如果 write pos 追上了 checkpoint，就意味着 <strong>redo log 文件满了，这时 MySQL 不能再执行新的更新操作，也就是说 MySQL 会被阻塞</strong>（<em>因此所以针对并发量大的系统，适当设置 redo log 的文件大小非常重要</em>），此时<strong>会停下来将 Buffer Pool 中的脏页刷新到磁盘中，然后标记 redo log 哪些记录可以被擦除，接着对旧的 redo log 记录进行擦除，等擦除完旧记录腾出了空间，checkpoint 就会往后移动（图中顺时针）</strong>，然后 MySQL 恢复正常运行，继续执行新的更新操作。</p><p>所以，一次 checkpoint 的过程就是脏页刷新到磁盘中变成干净页，然后标记 redo log 哪些记录可以被覆盖的过程</p><h2 id="_2-4-bin-log" tabindex="-1"><a class="header-anchor" href="#_2-4-bin-log" aria-hidden="true">#</a> 2.4 bin log</h2><p>MySQL 在完成一条更新操作后，Server 层还会生成一条 binlog，等之后事务提交的时候，会将该事物执行过程中产生的所有 binlog 统一写 入 binlog 文件。</p><p>binlog 文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作，比如 SELECT 和 SHOW 操作。</p><h3 id="bin-log-和-redo-log-的区别" tabindex="-1"><a class="header-anchor" href="#bin-log-和-redo-log-的区别" aria-hidden="true">#</a> bin log 和 redo log 的区别</h3><p>有四个区别：</p><ol><li><em>适用对象不同：</em><ul><li>binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用；</li><li>redo log 是 Innodb 存储引擎实现的日志；</li></ul></li><li><em>文件格式不同：</em><ul><li>binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED，区别如下： <ul><li>STATEMENT：每一条修改数据的 SQL 都会被记录到 binlog 中（相当于记录了逻辑操作，所以针对这种格式， binlog 可以称为逻辑日志），主从复制中 slave 端再根据 SQL 语句重现。但 STATEMENT 有动态函数的问题，比如你用了 uuid 或者 now 这些函数，你在主库上执行的结果并不是你在从库执行的结果，这种随时在变的函数会导致复制的数据不一致；</li><li>ROW：记录行数据最终被修改成什么样了（这种格式的日志，就不能称为逻辑日志了），不会出现 STATEMENT 下动态函数的问题。但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已；</li><li>MIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式；</li></ul></li><li>redo log 是物理日志，记录的是在某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新；</li></ul></li><li><em>写入方式不同：</em><ul><li>binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。</li><li>redo log 是循环写，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志。</li></ul></li><li><em>用途不同：</em><ul><li>binlog 用于备份恢复、主从复制；</li><li>redo log 用于掉电等故障恢复。</li></ul></li></ol><h3 id="主从复制" tabindex="-1"><a class="header-anchor" href="#主从复制" aria-hidden="true">#</a> 主从复制</h3><p>MySQL 的主从复制依赖于 binlog ，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上。复制的过程就是将 binlog 中的数据从主库传输到从库上。</p><p>这个过程一般是<strong>异步</strong>的，也就是主库上执行事务操作的线程不会等待复制 binlog 的线程同步完成。</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/主从复制过程.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="MySQL 主从复制过程" tabindex="0" loading="lazy"><figcaption>MySQL 主从复制过程</figcaption></figure><p>MySQL 集群的主从复制过程梳理成 3 个阶段：</p><ul><li><strong>写入 Binlog</strong>：主库写 binlog 日志，提交事务，并更新本地存储数据。</li><li><strong>同步 Binlog</strong>：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。</li><li><strong>回放 Binlog</strong>：回放 binlog，并更新存储引擎中的数据。</li></ul><p>具体详细过程如下：</p><ul><li>MySQL 主库在收到客户端提交事务的请求之后，会先写入 binlog，再提交事务，更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。</li><li>从库会创建一个专门的 I/O 线程，连接主库的 log dump 线程，来接收主库的 binlog 日志，再把 binlog 信息写入 relay log 的中继日志里，再返回给主库“复制成功”的响应。</li><li>从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。</li></ul><p>在完成主从复制之后，你就可以在写数据时只写主库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响读请求的执行。</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/主从架构.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="MySQL 主从架构" tabindex="0" loading="lazy"><figcaption>MySQL 主从架构</figcaption></figure><h4 id="mysql-主从复制还有哪些模型" tabindex="-1"><a class="header-anchor" href="#mysql-主从复制还有哪些模型" aria-hidden="true">#</a> MySQL 主从复制还有哪些模型</h4><ul><li><strong>同步复制</strong>：MySQL 主库提交事务的线程要等待所有从库的复制成功响应，才返回客户端结果。这种方式在实际项目中，基本上没法用，原因有两个：一是性能很差，因为要复制到所有节点才返回响应；二是可用性也很差，主库和所有从库任何一个数据库出问题，都会影响业务。</li><li><strong>异步复制</strong>（默认模型）：MySQL 主库提交事务的线程并不会等待 binlog 同步到各从库，就返回客户端结果。这种模式一旦主库宕机，数据就会发生丢失。</li><li><strong>半同步复制</strong>：MySQL 5.7 版本之后增加的一种复制方式，介于两者之间，事务线程不用等待所有的从库复制成功响应，只要一部分复制成功响应回来就行，比如一主二从的集群，只要数据成功复制到任意一个从库上，主库的事务线程就可以返回给客户端。这种<strong>半同步复制的方式，兼顾了异步复制和同步复制的优点，即使出现主库宕机，至少还有一个从库有最新的数据，不存在数据丢失的风险</strong>。</li></ul><h3 id="bin-log-何时写入磁盘" tabindex="-1"><a class="header-anchor" href="#bin-log-何时写入磁盘" aria-hidden="true">#</a> bin log 何时写入磁盘</h3><p>事务执行过程中，先把日志写到 binlog cache（Server 层的 cache），事务提交的时候，再把 binlog cache 写到 binlog 文件中。</p><p>一个事务的 binlog 是不能被拆开的，因此无论这个事务有多大（比如有很多条语句），也要保证一次性写入。这是因为有一个线程只能同时有一个事务在执行的设定，所以每当执行一个 begin/start transaction 的时候，就会默认提交上一个事务，这样如果一个事务的 binlog 被拆开的时候，在备库执行就会被当做多个事务分段自行，这样破坏了原子性，是有问题的。</p><p>MySQL 给每个线程分配了一片内存用于缓冲 binlog ，该内存叫 binlog cache，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。</p><p>在事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 文件中，并清空 binlog cache。如下图：</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/binlogcache.drawio.png" alt="binlog cach" tabindex="0" loading="lazy"><figcaption>binlog cach</figcaption></figure><p>虽然每个线程有自己 binlog cache，但是最终都写到同一个 binlog 文件：</p><ul><li>图中的 write，指的就是指把日志写入到 binlog 文件，但是并没有把数据持久化到磁盘，因为数据还缓存在文件系统的 page cache 里，write 的写入速度还是比较快的，因为不涉及磁盘 I/O。</li><li>图中的 fsync，才是将数据持久化到磁盘的操作，这里就会涉及磁盘 I/O，所以频繁的 fsync 会导致磁盘的 I/O 升高。</li></ul><p>MySQL提供一个 sync_binlog 参数来控制数据库的 binlog 刷到磁盘上的频率：</p><ul><li>sync_binlog = 0 的时候，表示每次提交事务都只 write，不 fsync，后续交由操作系统决定何时将数据持久化到磁盘；</li><li>sync_binlog = 1 的时候，表示每次提交事务都会 write，然后马上执行 fsync；</li><li>sync_binlog =N(N&gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。</li></ul><p>在MySQL中系统默认的设置是 sync_binlog = 0，也就是不做任何强制性的磁盘刷新指令，这时候的性能是最好的，但是风险也是最大的。因为一旦主机发生异常重启，还没持久化到磁盘的数据就会丢失。</p><p>而当 sync_binlog 设置为 1 的时候，是最安全但是性能损耗最大的设置。因为当设置为 1 的时候，即使主机发生异常重启，最多丢失一个事务的 binlog，而已经持久化到磁盘的数据就不会有影响，不过就是对写入性能影响太大。</p><p>如果能容少量事务的 binlog 日志丢失的风险，为了提高写入的性能，一般会 sync_binlog 设置为 100~1000 中的某个数值。</p><h2 id="_2-5-两阶段提交" tabindex="-1"><a class="header-anchor" href="#_2-5-两阶段提交" aria-hidden="true">#</a> 2.5 两阶段提交</h2><p>事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现半成功的状态，这样就造成两份日志之间的逻辑不一致。</p><p>在持久化 redo log 和 binlog 这两份日志的时候，如果出现半成功的状态，就会造成主从环境的数据不一致性。这是因为 redo log 影响主库的数据，binlog 影响从库的数据，所以 redo log 和 binlog 必须保持一致才能保证主从数据一致。</p><p><strong>MySQL 为了避免出现两份日志之间的逻辑不一致的问题，使用了「两阶段提交」来解决</strong>，两阶段提交其实是分布式事务一致性协议，它可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的状态。</p><p><strong>两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是「准备（Prepare）阶段」和「提交（Commit）阶段」</strong>，每个阶段都由协调者（Coordinator）和参与者（Participant）共同完成。注意，不要把提交（Commit）阶段和 commit 语句混淆了，commit 语句执行的时候，会包含提交（Commit）阶段。</p><h3 id="流程" tabindex="-1"><a class="header-anchor" href="#流程" aria-hidden="true">#</a> 流程</h3><p>在 MySQL 的 InnoDB 存储引擎中，开启 binlog 的情况下，MySQL 会同时维护 binlog 日志与 InnoDB 的 redo log，为了保证这两个日志的一致性，MySQL 使用了<strong>内部 XA 事务</strong>。</p><p>当客户端执行 commit 语句或者在自动提交的情况下，MySQL 内部开启一个 XA 事务，<strong>分两阶段来完成 XA 事务的提交</strong>，如下图：</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/两阶段提交.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="两阶段提交" tabindex="0" loading="lazy"><figcaption>两阶段提交</figcaption></figure><p>从图中可看出，事务的提交过程有两个阶段，就是<strong>将 redo log 的写入拆成了两个步骤：prepare 和 commit，中间再穿插写入binlog</strong>，具体如下：</p><ul><li><strong>prepare 阶段</strong>：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘（innodb_flush_log_at_trx_commit = 1 的作用）；</li><li><strong>commit 阶段</strong>：把 XID 写入到 binlog，然后将 binlog 持久化到磁盘（sync_binlog = 1 的作用），接着调用引擎的提交事务接口，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到文件系统的 page cache 中就够了，因为只要 binlog 写磁盘成功，就算 redo log 的状态还是 prepare 也没有关系，一样会被认为事务已经执行成功</li></ul><h3 id="异常重启会出现什么现象" tabindex="-1"><a class="header-anchor" href="#异常重启会出现什么现象" aria-hidden="true">#</a> 异常重启会出现什么现象？</h3><p>我们来看看在两阶段提交的不同时刻，MySQL 异常重启会出现什么现象？下图中有时刻 A 和时刻 B 都有可能发生崩溃：</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/两阶段提交崩溃点.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="时刻 A 与时刻 B" tabindex="0" loading="lazy"><figcaption>时刻 A 与时刻 B</figcaption></figure><p>不管是时刻 A（redo log 已经写入磁盘， binlog 还没写入磁盘），还是时刻 B （redo log 和 binlog 都已经写入磁盘，还没写入 commit 标识）崩溃，<strong>此时的 redo log 都处于 prepare 状态</strong>。</p><p>在 MySQL 重启后会按顺序扫描 redo log 文件，碰到处于 prepare 状态的 redo log，就拿着 redo log 中的 XID 去 binlog 查看是否存在此 XID：</p><ul><li><strong>如果 binlog 中没有当前内部 XA 事务的 XID，说明 redolog 完成刷盘，但是 binlog 还没有刷盘，则回滚事务</strong>。对应时刻 A 崩溃恢复的情况。</li><li><strong>如果 binlog 中有当前内部 XA 事务的 XID，说明 redolog 和 binlog 都已经完成了刷盘，则提交事务</strong>。对应时刻 B 崩溃恢复的情况。</li></ul><p>可以看到，<strong>对于处于 prepare 阶段的 redo log，即可以提交事务，也可以回滚事务，这取决于是否能在 binlog 中查找到与 redo log 相同的 XID</strong>，如果有就提交事务，如果没有就回滚事务。这样就可以保证 redo log 和 binlog 这两份日志的一致性了。</p><p>所以说，<strong>两阶段提交是以 binlog 写成功为事务提交成功的标识</strong>，因为 binlog 写成功了，就意味着能在 binlog 中查找到与 redo log 相同的 XID。</p><h3 id="处于-prepare-阶段的-redo-log-加上完整-binlog-重启就提交事务-mysql-为什么要这么设计" tabindex="-1"><a class="header-anchor" href="#处于-prepare-阶段的-redo-log-加上完整-binlog-重启就提交事务-mysql-为什么要这么设计" aria-hidden="true">#</a> 处于 prepare 阶段的 redo log 加上完整 binlog，重启就提交事务，MySQL 为什么要这么设计?</h3><p>binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。</p><p>所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。</p><h3 id="事务没提交的时候-redo-log-会被持久化到磁盘吗" tabindex="-1"><a class="header-anchor" href="#事务没提交的时候-redo-log-会被持久化到磁盘吗" aria-hidden="true">#</a> 事务没提交的时候，redo log 会被持久化到磁盘吗？</h3><p>会的。</p><p>事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些缓存在 redo log buffer 里的 redo log 也会被「后台线程」每隔一秒一起持久化到磁盘。</p><p>也就是说，<strong>事务没提交的时候，redo log 也是可能被持久化到磁盘的</strong>。</p><p>如果 mysql 崩溃了，还没提交事务的 redo log 已经被持久化磁盘了，mysql 重启后，数据不就不一致了？</p><p>这种情况 mysql 重启会进行回滚操作，因为事务没提交的时候，binlog 是还没持久化到磁盘的。</p><p>所以， redo log 可以在事务没提交之前持久化到磁盘，但是 binlog 必须在事务提交之后，才可以持久化到磁盘。</p><h2 id="_2-6-组提交" tabindex="-1"><a class="header-anchor" href="#_2-6-组提交" aria-hidden="true">#</a> 2.6 组提交</h2><h3 id="两阶段提交的性能问题" tabindex="-1"><a class="header-anchor" href="#两阶段提交的性能问题" aria-hidden="true">#</a> 两阶段提交的性能问题</h3><p>两阶段提交虽然保证了两个日志文件的数据一致性，但是性能很差，主要有两个方面的影响：</p><ul><li><strong>磁盘 I/O 次数高</strong>：对于“双1”配置，每个事务提交都会进行两次 fsync（刷盘），一次是 redo log 刷盘，另一次是 binlog 刷盘。</li><li><strong>锁竞争激烈</strong>：两阶段提交虽然能够保证「单事务」两个日志的内容一致，但在「多事务」的情况下，却不能保证两者的提交顺序一致，因此，在两阶段提交的流程基础上，还需要加一个锁来保证提交的原子性，从而保证多事务的情况下，两个日志的提交顺序一致。</li></ul><h3 id="组提交" tabindex="-1"><a class="header-anchor" href="#组提交" aria-hidden="true">#</a> 组提交</h3><p><strong>MySQL 引入了 binlog 组提交（group commit）机制，当有多个事务提交的时候，会将多个 binlog 刷盘操作合并成一个，从而减少磁盘 I/O 的次数</strong>，如果说 10 个事务依次排队刷盘的时间成本是 10，那么将这 10 个事务一次性一起刷盘的时间成本则近似于 1。</p><p>引入了组提交机制后，prepare 阶段不变，只针对 commit 阶段，将 commit 阶段拆分为三个过程：</p><ul><li><strong>flush 阶段</strong>：多个事务按进入的顺序将 binlog 从 cache 写入文件（不刷盘）；</li><li><strong>sync 阶段</strong>：对 binlog 文件做 fsync 操作（多个事务的 binlog 合并一次刷盘）；</li><li><strong>commit 阶段</strong>：各个事务按顺序做 InnoDB commit 操作；</li></ul><p>上面的<strong>每个阶段都有一个队列</strong>，每个阶段有锁进行保护，因此保证了事务写入的顺序，第一个进入队列的事务会成为 leader，leader领导所在队列的所有事务，全权负责整队的操作，完成后通知队内其他事务操作结束。</p><figure><img src="http://keithlan.github.io/image/mysql_innodb_arch/commit_4.png" alt="每个阶段都有一个队列" tabindex="0" loading="lazy"><figcaption>每个阶段都有一个队列</figcaption></figure><p>对每个阶段引入了队列后，锁就只针对每个队列进行保护，不再锁住提交事务的整个过程，可以看的出来，<strong>锁粒度减小了，这样就使得多个阶段可以并发执行，从而提升效率</strong>。</p><h3 id="flush-阶段" tabindex="-1"><a class="header-anchor" href="#flush-阶段" aria-hidden="true">#</a> flush 阶段</h3><p>第一个事务会成为 flush 阶段的 Leader，此时后面到来的事务都是 Follower ：</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/组提交1.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>接着，获取队列中的事务组，由绿色事务组的 Leader 对 redo log 做一次 write + fsync，即一次将同组事务的 redolog 刷盘：</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/组提交2.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>完成了 prepare 阶段后，将绿色这一组事务执行过程中产生的 binlog 写入 binlog 文件（调用 write，不会调用 fsync，所以不会刷盘，binlog 缓存在操作系统的文件系统中）。</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/write_binlog.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>从上面这个过程，可以知道 flush 阶段队列的作用是<strong>用于支撑 redo log 的组提交</strong>。</p><p>如果在这一步完成后数据库崩溃，由于 binlog 中没有该组事务的记录，所以 MySQL 会在重启后回滚该组事务。</p><h3 id="sync-阶段" tabindex="-1"><a class="header-anchor" href="#sync-阶段" aria-hidden="true">#</a> sync 阶段</h3><p>绿色这一组事务的 binlog 写入到 binlog 文件后，并不会马上执行刷盘的操作，而是<strong>会等待一段时间</strong>，这个等待的时长由 <code>Binlog_group_commit_sync_delay</code> 参数控制，<strong>目的是为了组合更多事务的 binlog，然后再一起刷盘</strong>，如下过程：</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/组提交4.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>不过，在等待的过程中，如果事务的数量提前达到了 <code>Binlog_group_commit_sync_no_delay_count</code> 参数设置的值，就不用继续等待了，就马上将 binlog 刷盘，如下图：</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/组提交5.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>从上面的过程，可以知道 sync 阶段队列的作用是<strong>用于支持 binlog 的组提交</strong>。</p><p>如果想提升 binlog 组提交的效果，可以通过设置下面这两个参数来实现：</p><ul><li><code>binlog_group_commit_sync_delay= N</code>，表示在等待 N 微妙后，直接调用 fsync，将处于文件系统中 page cache 中的 binlog 刷盘，也就是将「 binlog 文件」持久化到磁盘。</li><li><code>binlog_group_commit_sync_no_delay_count = N</code>，表示如果队列中的事务数达到 N 个，就忽视binlog_group_commit_sync_delay 的设置，直接调用 fsync，将处于文件系统中 page cache 中的 binlog 刷盘。</li></ul><p>如果在这一步完成后数据库崩溃，由于 binlog 中已经有了事务记录，MySQL会在重启后通过 redo log 刷盘的数据继续进行事务的提交。</p><h3 id="commit-阶段" tabindex="-1"><a class="header-anchor" href="#commit-阶段" aria-hidden="true">#</a> commit 阶段</h3><p>最后进入 commit 阶段，调用引擎的提交事务接口，将 redo log 状态设置为 commit。</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/组提交6.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>commit 阶段队列的作用是承接 sync 阶段的事务，完成最后的引擎提交，使得 sync 可以尽早的处理下一组事务，最大化组提交的效率</p><h2 id="_2-7-update-语句的执行过程" tabindex="-1"><a class="header-anchor" href="#_2-7-update-语句的执行过程" aria-hidden="true">#</a> 2.7 Update 语句的执行过程</h2><p>当优化器分析出成本最小的执行计划后，执行器就按照执行计划开始进行更新操作。</p><p>具体更新一条记录 <code>UPDATE t_user SET name = &#39;xiaolin&#39; WHERE id = 1;</code> 的流程如下:</p><ol><li>执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录： <ul><li>如果 id=1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新；</li><li>如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。</li></ul></li><li>执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样： <ul><li>如果一样的话就不进行后续更新流程；</li><li>如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；</li></ul></li><li>开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在内存修改该 Undo 页面后，需要记录对应的 redo log。</li><li>InnoDB 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 <strong>WAL 技术</strong>，MySQL 的写操作并不是立刻写到磁盘上，而是先写 redo 日志，然后在合适的时间再将修改的行数据写到磁盘上。</li><li>至此，一条记录更新完了。</li><li>在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。</li><li>事务提交（为了方便说明，这里不说组提交的过程，只说两阶段提交）： <ul><li><strong>prepare 阶段</strong>：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；</li><li><strong>commit 阶段</strong>：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件）；</li></ul></li><li>至此，一条更新语句执行完成。</li></ol>',169),r=[g];function a(t,d){return i(),l("div",null,r)}const p=o(e,[["render",a],["__file","5.log.html.vue"]]);export{p as default};

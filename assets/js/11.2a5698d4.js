(window.webpackJsonp=window.webpackJsonp||[]).push([[11],{624:function(s,t,a){s.exports=a.p+"assets/img/640.c9e2ece8.jpeg"},625:function(s,t,a){s.exports=a.p+"assets/img/640-16480900289396.324da90b.png"},626:function(s,t,a){s.exports=a.p+"assets/img/640-16480905734318.5dbd0e85.png"},627:function(s,t,a){s.exports=a.p+"assets/img/640-164809062250110.8a261d22.png"},628:function(s,t,a){s.exports=a.p+"assets/img/640-164809160525512.e4c9e8f9.png"},629:function(s,t,a){s.exports=a.p+"assets/img/640-164809182080214.7383e023.png"},630:function(s,t,a){s.exports=a.p+"assets/img/640-164809387798316.1105a48b.png"},724:function(s,t,a){"use strict";a.r(t);var n=a(5),e=Object(n.a)({},(function(){var s=this,t=s.$createElement,n=s._self._c||t;return n("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[n("h2",{attrs:{id:"_1-简介"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-简介"}},[s._v("#")]),s._v(" 1. 简介")]),s._v(" "),n("p",[s._v("minidb 为 rosedb 的 mini 版本，用于理解 bitcask 存储模型以及 rosedb。")]),s._v(" "),n("p",[s._v("minidb 中没有实现 bitcask 模型的多个数据文件机制，为了简化只使用了一个数据文件进行读写，但不妨碍理解 bitcask 模型。")]),s._v(" "),n("h2",{attrs:{id:"_2-存储模型"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-存储模型"}},[s._v("#")]),s._v(" 2. 存储模型")]),s._v(" "),n("p",[s._v("存储，其核心问题是：如何存放数据以及如何取出数据。")]),s._v(" "),n("p",[s._v("计算机中有内存和磁盘，内存是易失性的，掉电之后数据全部丢失，所以想要在系统崩溃重启后依然正常使用，需要将数据存储在非易失介质中（如磁盘等）。")]),s._v(" "),n("p",[s._v("那么对于一个单机版的 k-v 存储引擎，我们需要设计数据在内存中应该如何存放，在磁盘中应该如何存放。根据优秀前辈的研究和总结，主要将数据存储模型分为两类："),n("mark",[s._v("B+ 树")]),s._v(" 和 "),n("mark",[s._v("LSM 树")]),s._v("。")]),s._v(" "),n("h3",{attrs:{id:"_2-1-b-树"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-b-树"}},[s._v("#")]),s._v(" 2.1 B+ 树")]),s._v(" "),n("p",[n("img",{attrs:{src:a(624),alt:"图片"}})]),s._v(" "),n("p",[s._v("B+ 树由二叉查找树演化而来，通过增加每层节点的数量，来降低树的高度，适配磁盘的页，尽量减少磁盘 IO 操作。")]),s._v(" "),n("p",[s._v("B+ 树查询性能比较稳定，在写入或更新时，会查找并定位到磁盘中的位置并进行原地操作，注意这里是随机 IO，并且大量的插入或删除还有可能触发页分裂和合并，写入性能一般，因此 B+ 树适合 "),n("mark",[s._v("读多写少")]),s._v(" 的场景。")]),s._v(" "),n("h3",{attrs:{id:"_2-2-lsm-树"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-lsm-树"}},[s._v("#")]),s._v(" 2.2 LSM 树")]),s._v(" "),n("p",[n("img",{attrs:{src:a(625),alt:"图片"}})]),s._v(" "),n("p",[s._v("LSM Tree (Log Structured Merge Tree, 日志结构合并树) 其实不是一种具体的树类型的数据结构，而是一种数据存储模型，其核心思想基于一个事实："),n("mark",[s._v("顺序 IO 远快于随机 IO")]),s._v("。")]),s._v(" "),n("p",[s._v("和 B+ 树不同，在 LSM 中数据的插入、更新、删除都会被记录成一条日志，然后追加写入到磁盘文件当中，这样所有的操作都是顺序 IO，因此 LSM 树适用于 "),n("mark",[s._v("写多读少")]),s._v(" 的场景。")]),s._v(" "),n("h2",{attrs:{id:"_3-minidb"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-minidb"}},[s._v("#")]),s._v(" 3. minidb")]),s._v(" "),n("p",[s._v("minidb 基于一种更加简单的存储结构，总体上和 LSM 类似。下面通过简单例子看下 minidb 当中数据的 PUT、GET、DELETE 流程。")]),s._v(" "),n("h3",{attrs:{id:"_3-1-put"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-put"}},[s._v("#")]),s._v(" 3.1 PUT")]),s._v(" "),n("p",[s._v("我们需要存储一条记录，分别是 key 和 value。首先，为防止数据丢失，我们会将 key 和 value 封装成一条记录（称作 Entry），追加到磁盘文件中。Entry 的大致由 key、value、key size、value size、写入时间组成。")]),s._v(" "),n("p",[n("img",{attrs:{src:a(626),alt:"图片"}})]),s._v(" "),n("p",[s._v("那么磁盘文件的结构非常简单，就是多个 Entry 的集合。")]),s._v(" "),n("p",[n("img",{attrs:{src:a(627),alt:"图片"}})]),s._v(" "),n("p",[n("mark",[s._v("磁盘更新完了，再来更新内存")]),s._v("， 内存当中可以选择一个简单的数据结构，如哈希表。哈希表的 key 对应存放的是 Entry 在磁盘中的位置，便于查找时进行获取。")]),s._v(" "),n("p",[s._v("至此 minidb 的数据存储的流程结束了，只有两个步骤： 一次磁盘记录的追加，一次内存当中的索引更新。")]),s._v(" "),n("h3",{attrs:{id:"_3-2-get"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-get"}},[s._v("#")]),s._v(" 3.2 GET")]),s._v(" "),n("p",[s._v("获取一条数据，首先在内存中的哈希表查找到 key 对应的索引信息，其中包含了的 value 存储在磁盘文件中的位置，然后直接根据这个位置，在磁盘中取出 value 即可。")]),s._v(" "),n("h3",{attrs:{id:"_3-3-del"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-del"}},[s._v("#")]),s._v(" 3.3 DEL")]),s._v(" "),n("p",[s._v("删除操作，并不会定位到原记录进行删除，而是首先将删除的操作封装成 Entry，追加到磁盘中，只是需要标识 Entry 的类型是删除。")]),s._v(" "),n("p",[s._v("之后在内存当中的哈希表删除对应的 key 的索引信息，至此删除操作便完成了。")]),s._v(" "),n("p",[s._v("可以看到，无论是插入、查询、删除都只有两个步骤："),n("mark",[s._v("一次内存中的索引更新，一次磁盘文件的记录追加")]),s._v("。所以无论数据规模如何，minidb 的写入性能较为稳定。")]),s._v(" "),n("h3",{attrs:{id:"_3-4-merge"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-merge"}},[s._v("#")]),s._v(" 3.4 Merge")]),s._v(" "),n("p",[s._v("最后再来看下一个比较重要的操作，由于磁盘记录一直在追加写入的，导致文件容量会一直增加。并且对于同一个 key，可能会在文件中存在多条 Entry（更新和删除 key 也会追加记录），那么在数据文件中，其实存在冗余的 Entry 数据。")]),s._v(" "),n("p",[s._v("例如，针对 key A，先后设其 value 为 10、20、30，那么磁盘就会存在三条记录：")]),s._v(" "),n("p",[n("img",{attrs:{src:a(628),alt:"图片"}})]),s._v(" "),n("p",[s._v("此时 A 的最新值是 30，那么前两条记录已经是无效的了。")]),s._v(" "),n("p",[s._v("针对上述情形，我们需要定期合并数据文件，清理无效的 Entry 数据，这个过程一般叫做 "),n("mark",[s._v("merge")]),s._v("。")]),s._v(" "),n("p",[s._v("Merge 的思路也较为简单，取出原数据文件的所有 Entry，将有效的 Entry 重新写入到一个新建的临时文件中，最后将原数据文件删除，临时文件就是新的数据文件了。")]),s._v(" "),n("p",[n("img",{attrs:{src:a(629),alt:"图片"}})]),s._v(" "),n("p",[s._v("这就是 minidb 的底层数据存储模型，名为 "),n("mark",[s._v("bitcask")]),s._v("，rosedb 也是采用这种模型。其本质属于类 LSM 模型，核心思想是利用顺序 IO 来提升写性能，只不过在实现上比 LSM 简单。")]),s._v(" "),n("h2",{attrs:{id:"_4-代码实现"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-代码实现"}},[s._v("#")]),s._v(" 4. 代码实现")]),s._v(" "),n("p",[s._v("下面看下几个核心步骤的 Code 实现")]),s._v(" "),n("h3",{attrs:{id:"_4-1-open"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-1-open"}},[s._v("#")]),s._v(" 4.1 Open")]),s._v(" "),n("p",[s._v("打开数据库，需要先加载数据文件，取出文件中的 Entry 数据，还原索引状态，关键代码如下：")]),s._v(" "),n("div",{staticClass:"language-go line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-go"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("func")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("Open")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dirPath "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("string")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("MiniDB"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("error")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 如果数据库目录不存在，则新建一个")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("_")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" err "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":=")]),s._v(" os"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("Stat")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dirPath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" os"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("IsNotExist")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("err"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" err "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":=")]),s._v(" os"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("MkdirAll")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dirPath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" os"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ModePerm"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" err "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("nil")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("nil")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" err\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n   "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 加载数据文件")]),s._v("\n   dbFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" err "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("NewDBFile")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dirPath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" err "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("nil")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("nil")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" err\n   "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n   db "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&")]),s._v("MiniDB"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      dbFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" dbFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      indexes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("make")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("map")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("string")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("int64")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      dirPath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" dirPath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n   "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 加载索引")]),s._v("\n   db"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("loadIndexesFromFile")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dbFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" db"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("nil")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br")])]),n("h3",{attrs:{id:"_4-2-put"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-2-put"}},[s._v("#")]),s._v(" 4.2 PUT")]),s._v(" "),n("p",[s._v("先更新磁盘，写入一条记录，再更新内存：")]),s._v(" "),n("div",{staticClass:"language-go line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-go"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("func")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("db "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("MiniDB"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("Put")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("byte")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("byte")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("err "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("error")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  \n   offset "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":=")]),s._v(" db"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("dbFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Offset\n   "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 封装成 Entry")]),s._v("\n   entry "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("NewEntry")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" PUT"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 追加到数据文件当中")]),s._v("\n   err "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" db"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("dbFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("Write")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("entry"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n   "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 写到内存")]),s._v("\n   db"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("indexes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("string")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" offset\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br")])]),n("h3",{attrs:{id:"_4-3-get"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-3-get"}},[s._v("#")]),s._v(" 4.3 GET")]),s._v(" "),n("p",[s._v("从内存中去除索引信息，判断是否存在，不存在直接返回，存在则从硬盘中取出数据。")]),s._v(" "),n("div",{staticClass:"language-go line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-go"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("func")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("db "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("MiniDB"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("Get")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("byte")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("byte")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" err "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("error")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 从内存当中取出索引信息")]),s._v("\n   offset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" ok "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":=")]),s._v(" db"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("indexes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("string")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// key 不存在")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!")]),s._v("ok "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n   "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 从磁盘中读取数据")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("var")]),s._v(" e "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("Entry\n   e"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" err "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" db"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("dbFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("Read")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("offset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" err "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("nil")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&&")]),s._v(" err "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" io"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("EOF "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" e "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("nil")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      val "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" e"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Value\n   "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br")])]),n("h3",{attrs:{id:"_4-4-delete"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-4-delete"}},[s._v("#")]),s._v(" 4.4 DELETE")]),s._v(" "),n("p",[s._v("DEL 和 PUT 类似，只是 Entry 被标记为了 DEL，然后封装成了 Entry 写入到文件中：")]),s._v(" "),n("div",{staticClass:"language-go line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-go"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("func")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("db "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("MiniDB"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("Del")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("byte")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("err "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("error")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 从内存当中取出索引信息")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("_")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" ok "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":=")]),s._v(" db"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("indexes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("string")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// key 不存在，忽略")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!")]),s._v("ok "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n   "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 封装成 Entry 并写入")]),s._v("\n   e "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("NewEntry")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("nil")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" DEL"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   err "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" db"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("dbFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("Write")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("e"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" err "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("nil")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n   "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 删除内存中的 key")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("delete")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("db"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("indexes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("string")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br")])]),n("h3",{attrs:{id:"_4-5-merge"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-5-merge"}},[s._v("#")]),s._v(" 4.5 Merge")]),s._v(" "),n("p",[s._v("合并文件操作：")]),s._v(" "),n("div",{staticClass:"language-go line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-go"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("func")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("db "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("MiniDB"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("Merge")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("error")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 读取原数据文件中的 Entry")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      e"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" err "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":=")]),s._v(" db"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("dbFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("Read")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("offset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" err "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("nil")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" err "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" io"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("EOF "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("break")]),s._v("\n         "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n         "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" err\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 内存中的索引状态是最新的，直接对比过滤出有效的 Entry")]),s._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" off"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" ok "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":=")]),s._v(" db"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("indexes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("string")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("e"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" ok "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&&")]),s._v(" off "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" offset "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         validEntries "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("append")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("validEntries"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" e"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      offset "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" e"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("GetSize")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("len")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("validEntries"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 新建临时文件")]),s._v("\n      mergeDBFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" err "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("NewMergeDBFile")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("db"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("dirPath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" err "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("nil")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" err\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("defer")]),s._v(" os"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("Remove")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("mergeDBFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("File"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("Name")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 重新写入有效的 entry")]),s._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("_")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" entry "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("range")]),s._v(" validEntries "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         writeOff "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":=")]),s._v(" mergeDBFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Offset\n         err "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":=")]),s._v(" mergeDBFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("Write")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("entry"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n         "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" err "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("nil")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" err\n         "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n         "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 更新索引")]),s._v("\n         db"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("indexes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("string")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("entry"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" writeOff\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 删除旧的数据文件")]),s._v("\n      os"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("Remove")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("db"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("dbFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("File"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("Name")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 临时文件变更为新的数据文件")]),s._v("\n      os"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("Rename")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("mergeDBFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("File"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("Name")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" db"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("dirPath"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("string")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("os"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("PathSeparator"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("FileName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n      db"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("dbFile "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" mergeDBFile\n   "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("nil")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br"),n("span",{staticClass:"line-number"},[s._v("42")]),n("br"),n("span",{staticClass:"line-number"},[s._v("43")]),n("br"),n("span",{staticClass:"line-number"},[s._v("44")]),n("br"),n("span",{staticClass:"line-number"},[s._v("45")]),n("br"),n("span",{staticClass:"line-number"},[s._v("46")]),n("br")])]),n("h2",{attrs:{id:"_5-小结"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_5-小结"}},[s._v("#")]),s._v(" 5. 小结")]),s._v(" "),n("p",[s._v("除去测试文件，minidb 的==核心代码只有300行==，但包含了 bitcask 存储模型的主要思想，并且也是 rosedb 的底层基础。")]),s._v(" "),n("p",[s._v("虽然 bitcask 简单易懂，但是也存在不少问题，在 rosedb 中也对其进行了优化。")]),s._v(" "),n("p",[s._v("bitcask 最初源于 Riak 项目的底层存储模型，而 Riak 是一个分布式 k-v 存储，在 NoSQL 的排名中也名列前茅：")]),s._v(" "),n("p",[n("img",{attrs:{src:a(630),alt:"图片"}})]),s._v(" "),n("p",[s._v("豆瓣使用的分布式 k-v 存储，其实也是基于的 bitcask 模型，并对其进行了很多优化。但是纯粹基于 bitcask 的 k-v 存储并不多。")]),s._v(" "),n("h2",{attrs:{id:"reference"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#reference"}},[s._v("#")]),s._v(" Reference")]),s._v(" "),n("ol",[n("li",[n("a",{attrs:{href:"https://mp.weixin.qq.com/s/s8s6VtqwdyjthR6EtuhnUA",target:"_blank",rel:"noopener noreferrer"}},[s._v("从零实现一个 k-v 存储引擎"),n("OutboundLink")],1)]),s._v(" "),n("li",[n("a",{attrs:{href:"https://riak.com/assets/bitcask-intro.pdf",target:"_blank",rel:"noopener noreferrer"}},[s._v("bitcask"),n("OutboundLink")],1)])])])}),[],!1,null,null,null);t.default=e.exports}}]);